# -*- coding: utf-8 -*-
"""Atari Game

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1i6FM9kbx0YHnsIWkuX2ZQ7J9OGkV3o9X
"""

!wget http://www.atarimania.com/roms/Roms.rar

!mkdir /content/ROM/

!unrar e /content/Roms.rar /content/ROM/

!unzip /content/ROM/HC-ROMS.zip

!unzip /content/ROM/ROMS.zip

!pip install atari-py

!python -m atari_py.import_roms /content/ROM/

!pip install opencv-python
!pip install gym
!pip install stable-baselines3

import gym
from stable_baselines3.common.vec_env import VecFrameStack
from stable_baselines3.common.evaluation import evaluate_policy
from stable_baselines3.common.env_util import make_atari_env
import os 
from stable_baselines3 import A2C

env_name = 'Breakout-v0'
env = gym.make(env_name)

env.reset()

episodes = 5 # number of episodes to play

for episode in range(episodes): 
    obs = env.reset()  # reset the environment
    done = False
    score = 0

    while not done:
        # env.render()
        action = env.action_space.sample() # take a random action 
        obs, reward, done, info = env.step(action) # take a step in the environment 
        score += reward
    print("Episode {} finished    Score: {}".format(episode, score)) 

env.close()

env = make_atari_env(env_name, n_envs=4,seed = 0)
env = VecFrameStack(env, n_stack=4)

import cv2

log_path = os.path.join('Training', 'Logs')

model = A2C('CnnPolicy', env, verbose=1, tensorboard_log=log_path)

model.learn(total_timesteps=1000000)

a2c_path = os.path.join('Training', 'Saved Model','A2C_Breakout_Model')
model.save(a2c_path)

del model # remove the trained model from memory

model = A2C.load(a2c_path,env)

env = make_atari_env(env_name, n_envs=1,seed = 0)
env = VecFrameStack(env, n_stack=4)
evaluate_policy(model, env, n_eval_episodes=10,render = False)

